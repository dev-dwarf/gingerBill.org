<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Memory Allocation Strategies on gingerBill</title>
    <link>/series/memory-allocation-strategies/</link>
    <description>Recent content in Memory Allocation Strategies on gingerBill</description>
    <language>en-gb</language>
    <lastBuildDate>Sat, 16 Feb 2019 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="/series/memory-allocation-strategies/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Memory Allocation Strategies - Part 4</title>
      <link>/article/2019/02/16/memory-allocation-strategies-004/</link>
      <pubDate>Sat, 16 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/article/2019/02/16/memory-allocation-strategies-004/</guid>
      <description>Pool-Based Allocation In the previous article, we looked at the stack allocator, which was the natural evolution of the linear/arena allocator. In this article, I will cover the fixed-sized pool allocator.
A pool allocator is a bit different from the previous allocation strategies that I have covered. A pool splits the supplied backing buffer into chunks of equal size and keeps track of which of the chunks are free. When an allocation is wanted, a free chunk is given.</description>
    </item>
    
    <item>
      <title>Memory Allocation Strategies - Part 3</title>
      <link>/article/2019/02/15/memory-allocation-strategies-003/</link>
      <pubDate>Fri, 15 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/article/2019/02/15/memory-allocation-strategies-003/</guid>
      <description>Stack-Like (LIFO) Allocation In the previous article, we looked at the linear/arena allocator, which is the simplest of all memory allocators. In this article, I will cover the fixed-sized stack-like allocator. Throughout this article, I will refer to this allocator as a stack allocator.
Note: A stack-like allocator means that the allocator acts like a data structure following the last-in, first-out (LIFO) principle. This has nothing to do with the stack or the stack frame.</description>
    </item>
    
    <item>
      <title>Memory Allocation Strategies - Part 2</title>
      <link>/article/2019/02/08/memory-allocation-strategies-002/</link>
      <pubDate>Fri, 08 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/article/2019/02/08/memory-allocation-strategies-002/</guid>
      <description>Linear Allocation The first memory allocation strategy that I will cover is also one of the simplest ones: linear allocation. As the name suggests, memory is allocated linearly. Throughout this series, I will be using the concept of an allocator as a means to allocate this memory. A linear allocator, is also known by other names such as an Arena or Region-based allocator. In this article, I will refer to this allocator an a Arena.</description>
    </item>
    
    <item>
      <title>Memory Allocation Strategies - Part 1</title>
      <link>/article/2019/02/01/memory-allocation-strategies-001/</link>
      <pubDate>Fri, 01 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/article/2019/02/01/memory-allocation-strategies-001/</guid>
      <description>Memory allocation seems to be something many people struggle with. Many languages try to automatically handle memory for you using different strategies: garbage collection (GC), automatic reference counting (ARC), resource acquisition is initialization (RAII), and ownership semantics. However, trying to abstract away memory allocation comes at a higher cost than most people realize.
Most people are taught to think of memory in terms of the stack and the heap, where the stack is automatically grown for a procedure call, and the heap is some magical thing that you can use to get memory that needs to live longer than the stack.</description>
    </item>
    
  </channel>
</rss>
